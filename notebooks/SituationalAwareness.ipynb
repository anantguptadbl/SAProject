{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will push the riplet data to SPARK DATAFRAME\n",
    "\n",
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkConf,SparkContext\n",
    "\n",
    "# Conf\n",
    "spark_master_url=\"spark://ip-172-16-139-218:7077\"\n",
    "spark_app_name=\"SA\"\n",
    "spark_conf=SparkConf()\n",
    "spark_conf=spark_conf.setMaster(spark_master_url)\n",
    "sc=SparkContext(conf=spark_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the data into a single file for Companies and Predicates\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "def checkAscii(x):\n",
    "    return(all([False if ord(y) > 136 or ord(y) < 32 else True for y in x]))   \n",
    "\n",
    "def getLabel(x):\n",
    "    if(x.rfind('#') > x.rfind('/')):\n",
    "        return(x[x.rfind('#')+1:])\n",
    "    else:\n",
    "        return(x[x.rfind('/')+1:])\n",
    "\n",
    "FullData=pd.DataFrame(columns=['property','hasValue','CompanyName'])\n",
    "for curFile in os.listdir('/home/ubuntu/anant/SAProject/data'):\n",
    "    if('CompanyDataWithLocation' in curFile ):\n",
    "        curData=pd.read_csv('/home/ubuntu/anant/SAProject/data/{}'.format(curFile))\n",
    "        FullData=pd.concat([FullData,curData])\n",
    "        print(FullData.shape[0])\n",
    "FullData=FullData.merge(pd.DataFrame(FullData[FullData['property']=='http://www.w3.org/2000/01/rdf-schema#label'][['CompanyName','hasValue']].drop_duplicates().values,columns=['CompanyName','CompanyLabel']),left_on='CompanyName',right_on='CompanyName',how='inner')\n",
    "\n",
    "predicateList=pd.read_csv('/home/ubuntu/anant/SAProject/data/predicateList.txt')\n",
    "predicateList.columns=['property']\n",
    "predicateList['property']=predicateList['property'].map(lambda x : str(x).replace('>','').replace('<',''))\n",
    "FullData=FullData.merge(predicateList,left_on='property',right_on='property',how='inner')\n",
    "FullData['dataFilter']=FullData['hasValue'].map(lambda x : checkAscii(str(x)))\n",
    "FullData=FullData[FullData['dataFilter']==True][['property','hasValue','CompanyName','CompanyLabel']]\n",
    "FullData['propertyLabel']=FullData['property'].map(lambda x : getLabel(x))\n",
    "FullData['valueLabel']=FullData['hasValue'].map(lambda x : getLabel(str(x)))\n",
    "FullData=FullData[['CompanyLabel','propertyLabel','valueLabel']]\n",
    "for curColumn in FullData.columns.values:\n",
    "    FullData[curColumn]=FullData[curColumn].map(lambda x : ''.join([y for y in str(x) if ord(y) >= 32 and ord(y) <= 126]))\n",
    "    print(\"Completed for {} for table {}\".format(curColumn,'comp'))\n",
    "FullData.to_csv('/home/ubuntu/anant/SAProject/data/CompanyDataWithLocationFull.txt',index=False)\n",
    "del(FullData)\n",
    "\n",
    "FullData=pd.DataFrame(columns=['property','hasValue','Predicate'])\n",
    "for curFile in os.listdir('/home/ubuntu/anant/SAProject/data'):\n",
    "    if('PredicateDataWithLocation' in curFile ):\n",
    "        curData=pd.read_csv('/home/ubuntu/anant/SAProject/data/{}'.format(curFile))\n",
    "        FullData=pd.concat([FullData,curData])\n",
    "        print(FullData.shape[0])\n",
    "\n",
    "FullData['dataFilter']=FullData['hasValue'].map(lambda x : checkAscii(str(x)))\n",
    "FullData=FullData[FullData['dataFilter']==True][['property','hasValue','Predicate']]\n",
    "print(FullData.shape)\n",
    "FullData['propertyLabel']=FullData['property'].map(lambda x : getLabel(x))\n",
    "FullData['valueLabel']=FullData['hasValue'].map(lambda x : getLabel(str(x)))\n",
    "FullData['predicateLabel']=FullData['Predicate'].map(lambda x : getLabel(str(x)))\n",
    "FullData=FullData[['predicateLabel','propertyLabel','valueLabel']]\n",
    "for curColumn in FullData.columns.values:\n",
    "    FullData[curColumn]=FullData[curColumn].map(lambda x : ''.join([y for y in str(x) if ord(y) > 32 and ord(y) < 126]))\n",
    "    print(\"Completed for {} for table {}\".format(curColumn,'comp'))\n",
    "FullData.to_csv('/home/ubuntu/anant/SAProject/data/PredicateDataWithLocationFull.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100054\n",
      "200130\n",
      "300227\n",
      "400230\n",
      "500263\n",
      "603706\n",
      "703891\n",
      "803966\n",
      "904042\n",
      "1004388\n",
      "1104396\n",
      "1204402\n",
      "1304457\n",
      "1404473\n",
      "1504596\n",
      "1604759\n",
      "1704832\n",
      "1807165\n",
      "1907610\n",
      "2007654\n",
      "2107733\n",
      "2207829\n",
      "2308440\n",
      "2408525\n",
      "2508583\n",
      "2608644\n",
      "2708709\n",
      "2808819\n",
      "2908967\n",
      "3010152\n",
      "3110202\n",
      "3210348\n",
      "3310491\n",
      "3410545\n",
      "Completed for CompanyLabel for table comp\n",
      "Completed for propertyLabel for table comp\n",
      "Completed for valueLabel for table comp\n"
     ]
    }
   ],
   "source": [
    "# Combine all the data into a single file for all Companies sans Location\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "def checkAscii(x):\n",
    "    return(all([False if ord(y) > 136 or ord(y) < 32 else True for y in x]))   \n",
    "\n",
    "def getLabel(x):\n",
    "    if(x.rfind('#') > x.rfind('/')):\n",
    "        return(x[x.rfind('#')+1:])\n",
    "    else:\n",
    "        return(x[x.rfind('/')+1:])\n",
    "\n",
    "FullData=pd.DataFrame(columns=['property','hasValue','CompanyName'])\n",
    "for curFile in os.listdir('/home/ubuntu/anant/SAProject/data'):\n",
    "    if('CompanyDataSansLocation' in curFile ):\n",
    "        curData=pd.read_csv('/home/ubuntu/anant/SAProject/data/{}'.format(curFile))\n",
    "        FullData=pd.concat([FullData,curData])\n",
    "        print(FullData.shape[0])\n",
    "FullData=FullData.merge(pd.DataFrame(FullData[FullData['property']=='http://www.w3.org/2000/01/rdf-schema#label'][['CompanyName','hasValue']].drop_duplicates().values,columns=['CompanyName','CompanyLabel']),left_on='CompanyName',right_on='CompanyName',how='inner')\n",
    "\n",
    "predicateList=pd.read_csv('/home/ubuntu/anant/SAProject/data/predicateList.txt')\n",
    "predicateList.columns=['property']\n",
    "predicateList['property']=predicateList['property'].map(lambda x : str(x).replace('>','').replace('<',''))\n",
    "FullData=FullData.merge(predicateList,left_on='property',right_on='property',how='inner')\n",
    "FullData['dataFilter']=FullData['hasValue'].map(lambda x : checkAscii(str(x)))\n",
    "FullData=FullData[FullData['dataFilter']==True][['property','hasValue','CompanyName','CompanyLabel']]\n",
    "FullData['propertyLabel']=FullData['property'].map(lambda x : getLabel(x))\n",
    "FullData['valueLabel']=FullData['hasValue'].map(lambda x : getLabel(str(x)))\n",
    "FullData=FullData[['CompanyLabel','propertyLabel','valueLabel']]\n",
    "for curColumn in FullData.columns.values:\n",
    "    FullData[curColumn]=FullData[curColumn].map(lambda x : ''.join([y for y in str(x) if ord(y) >= 32 and ord(y) <= 126]))\n",
    "    print(\"Completed for {} for table {}\".format(curColumn,'comp'))\n",
    "FullData.to_csv('/home/ubuntu/anant/SAProject/data/CompanyDataSansLocationFull.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now we will work with only the Location Companies\n",
    "\n",
    "# Read the Company data and Concept data into different RDDs\n",
    "# Read the Company data\n",
    "companyData=sc.textFile('/home/ubuntu/anant/SAProject/data/CompanyDataWithLocationFull.txt.bz2')\n",
    "print(companyData.count())\n",
    "# Read the Predicate data\n",
    "predicateData=sc.textFile('/home/ubuntu/anant/SAProject/data/PredicateDataWithLocationFull.txt.bz2')\n",
    "print(predicateData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"steel america\"\n",
    "import csv\n",
    "\n",
    "# Row RDD\n",
    "#predicateData=predicateData.map(lambda x : list(csv.reader([x],delimiter=\",\"))[0])\n",
    "#companyData=companyData.map(lambda x : list(csv.reader([x],delimiter=\",\"))[0])\n",
    "\n",
    "# We will now apply filters\n",
    "#predicateFilter=predicateData.filter(lambda x : '_steel_' in str('_' + str(x[2]) + '_').lower())\n",
    "companyFilter=companyData.filter(lambda x : ' steel ' in str(x[2]).lower())\n",
    "#companyPredicateFilter=companyFilter.map(lambda x : (x[2],[x[0],x[1]])).join(predicateFilter.map(lambda x: (x[0],[x[1],x[2]]) ))\n",
    "\n",
    "# We will now get the list of companies from both these filters\n",
    "#companyFilter.map(lambda x : x[0]).distinct().take(5)\n",
    "\n",
    "#predicateFilter.take(5)\n",
    "\n",
    "#[x for x in FullData['valueLabel'] if 'steel' in str(x).lower()]\n",
    "#FullData['predicateLabel'].unique()\n",
    "#FullData.head(5)\n",
    "#predicateData=predicateData.map(lambda x : (list(csv.reader([x],delimiter=\",\"))[0][0],list(csv.reader([x],delimiter=\",\"))[0][1:3]) )\n",
    "#predicateData.take(5)\n",
    "#predicateData.take(5)\n",
    "#predicateData.map(lambda x : x[0]).take(5)\n",
    "#predicateData.filter(lambda x : 'steel' in str(x[0]) ).take(5)\n",
    "#predicateData.withColumn(\"filter\",lambda x : 'steel' in x[0].lower()).take(5)\n",
    "#predicateData.groupByKey().mapValues(lambda x: list(x)).filter(lambda x : ('steel' in x[0])==True).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for checking the simple thing on executor sc\n",
    "data=[1,2,3,4,5]\n",
    "dataRDD=sc.parallelize(data)\n",
    "\n",
    "def doSomething(x):\n",
    "    randomData=np.random.rand(10,1).flatten()\n",
    "    randomDataRDD=sc.parallelize(randomData)\n",
    "    return(randomDataRDD.count())\n",
    "\n",
    "dataRDD.map(lambda x : doSomething(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.rand(10,1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create a very simple RDF load it and make it availabe for querying through the frontend\n",
    "import rdflib\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "from rdflib.namespace import RDF, FOAF\n",
    "from rdflib import Graph\n",
    "\n",
    "bob = URIRef(\"http://example.org/people/Bob\")\n",
    "linda = BNode() # a GUID is generated\n",
    "\n",
    "name = Literal('Bob') # passing a string\n",
    "age = Literal(24) # passing a python int\n",
    "height = Literal(76.5) # passing a python float\n",
    "\n",
    "\n",
    "g = Graph()\n",
    "\n",
    "g.add( (bob, RDF.type, FOAF.Person) )\n",
    "g.add( (bob, FOAF.name, name) )\n",
    "g.add( (bob, FOAF.knows, linda) )\n",
    "g.add( (linda, RDF.type, FOAF.Person) )\n",
    "g.add( (linda, FOAF.name, Literal('Linda') ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get news data\n",
    "#\n",
    "#path_to_phatomJS='/home/ubuntu/recommendBot/flaskapp/phantomjs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also store the data as a simple numpy array/pandas dataframe\n",
    "\n",
    "data=[\n",
    "    ['appleInc','type','company'],\n",
    "    ['appleInc','products','Iphone'],\n",
    "    ['appleInc','products','Ipad'],\n",
    "    ['microsoft','type','company'],\n",
    "    ['microsoft','products','Windows'],\n",
    "    ['microsoft','products','Surface']\n",
    "]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
